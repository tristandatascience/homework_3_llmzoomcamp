{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0c7adf-5037-4479-b4b3-28edfd3a3714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\.virtualenvs\\llmzoomcamp-nAbKfTAh\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('multi-qa-distilbert-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211fefe0-bf3a-4022-922b-ecd467514b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"I just discovered the course. Can I still join it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c98467-32ef-4e29-866a-0a0260daf905",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector = embedding_model.encode(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbffc51-d328-4f7c-918a-6f565e45b216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07822264"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20865a8a-7336-4b8e-bd5f-43774cc920fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4128da34-e48a-4a87-95da-717415294976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99de0a56-29c3-4e09-b031-2de6ff3f53b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 375\n"
     ]
    }
   ],
   "source": [
    "documents = [doc for doc in documents if \"machine-learning-zoomcamp\" in doc['course']]\n",
    "print(f\"Number of documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071cbd16-10d9-4abc-b0eb-3f6b515eef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model = embedding_model\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for doc in documents:\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    qa_text = f'{question} {text}'\n",
    "    embedding = model.encode(qa_text)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "X = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351a6150-92d1-492d-a891-ba7f3778172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (375, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a3244-95c6-4f40-92ea-60fb5bd1fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 (375, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "040cc345-5a75-4eab-8087-15dd53c5cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X.dot(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99a0918-1ed5-4733-8fd7-f03c1c08fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score is: 0.6506574153900146\n"
     ]
    }
   ],
   "source": [
    "highest_score = scores.max()\n",
    "print(f\"The highest score is: {highest_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda02e03-bd59-4498-902c-1c18763ee688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 0.6506574153900146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aef765c1-2ea4-413f-b76f-d8894f9c9df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course has already started. Can I still join it?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'ee58a693'},\n",
       " {'text': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'I just joined. What should I do next? How can I access course materials?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '0a278fb2'},\n",
       " {'text': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': \"I filled the form, but haven't received a confirmation email. Is it normal?\",\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '6ba259b1'},\n",
       " {'text': 'Technically, yes. Advisable? Not really. Reasons:\\nSome homework(s) asks for specific python library versions.\\nAnswers may not match in MCQ options if using different languages other than Python 3.10 (the recommended version for 2023 cohort)\\nAnd as for midterms/capstones, your peer-reviewers may not know these other languages. Do you want to be penalized for others not knowing these other languages?\\nYou can create a separate repo using course’s lessons but written in other languages for your own learnings, but not advisable for submissions.\\ntx[source]',\n",
       "  'section': 'Miscellaneous',\n",
       "  'question': 'Can I do the course in other languages, like R or Scala?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '9f261648'},\n",
       " {'text': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course videos are from the previous iteration. Will you release new ones or we’ll use the videos from 2021?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'e7ba6b8a'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(embedding_vector)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(embedding_vector, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92927728-af50-4092-bae1-8168fd5ffab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48f87906-5fab-4137-9bf2-f4d947fefba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course has already started. Can I still join it?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'ee58a693'},\n",
       " {'text': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'I just joined. What should I do next? How can I access course materials?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '0a278fb2'},\n",
       " {'text': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': \"I filled the form, but haven't received a confirmation email. Is it normal?\",\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '6ba259b1'},\n",
       " {'text': 'Technically, yes. Advisable? Not really. Reasons:\\nSome homework(s) asks for specific python library versions.\\nAnswers may not match in MCQ options if using different languages other than Python 3.10 (the recommended version for 2023 cohort)\\nAnd as for midterms/capstones, your peer-reviewers may not know these other languages. Do you want to be penalized for others not knowing these other languages?\\nYou can create a separate repo using course’s lessons but written in other languages for your own learnings, but not advisable for submissions.\\ntx[source]',\n",
       "  'section': 'Miscellaneous',\n",
       "  'question': 'Can I do the course in other languages, like R or Scala?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '9f261648'},\n",
       " {'text': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course videos are from the previous iteration. Will you release new ones or we’ll use the videos from 2021?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'e7ba6b8a'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(embedding_vector, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bc3a8bb-8f7a-406d-8e29-b01b98f294c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5e98573-658f-43cc-8b96-ca076d1673fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [ doc['document'] for doc in ground_truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5cc14e32-5e7a-45b5-bf8b-e68e8208b5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result['id'] in l for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad0e2f8a-2901-4eda-b0c8-f4391c5aba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15ecb87b-ee21-483d-a636-6d0e3a8e89fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit-rate: 5.00\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "#total = len(set(l))\n",
    "total = len(l)\n",
    "for item in ground_truth:\n",
    "    query = item['question']\n",
    "    expected_id = item['document']\n",
    "    # Search\n",
    "    results = search_engine.search(embedding_vector, num_results=5)\n",
    "    \n",
    "    # Check if the expected document is in the results\n",
    "    if any(result['id'] == expected_id for result in results):\n",
    "        hits += 1\n",
    "\n",
    "print(f\"Hit-rate: {( hits / 5):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e043e26-37ee-43fb-b49a-4110f0fdd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33b579ec-7ab5-47c1-bfc5-55df3de878b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ml_zoomcamp'})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "index_name = \"ml_zoomcamp\"\n",
    "\n",
    "settings = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,  # Modifié pour correspondre à la dimension de nos embeddings\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text\": {\"type\": \"text\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(index=index_name, body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4ac0bcf3-febe-449c-b16b-3e088c6cfb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(documents):\n",
    "    es.index(index=index_name, id=doc['id'], body={\n",
    "        \"text\": doc['text'],\n",
    "        \"text_vector\": X[i].tolist()  # Convertir en liste pour JSON\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee473c82-8510-4e0b-bbfb-964b847ca08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID du document avec le score le plus élevé : ee58a693\n",
      "Score : 1.6506574\n"
     ]
    }
   ],
   "source": [
    "query = \"I just discovered the course. Can I still join it?\"\n",
    "query_vector = embedding_model.encode(query)\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 1,  # Nous ne voulons que le document avec le score le plus élevé\n",
    "    \"query\": {\n",
    "        \"script_score\": {\n",
    "            \"query\": {\"match_all\": {}},\n",
    "            \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.query_vector, 'text_vector') + 1.0\",\n",
    "                \"params\": {\"query_vector\": query_vector.tolist()}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=search_query)\n",
    "\n",
    "# Obtenir l'ID du document avec le score le plus élevé\n",
    "top_hit = response['hits']['hits'][0]\n",
    "top_id = top_hit['_id']\n",
    "top_score = top_hit['_score']\n",
    "\n",
    "print(f\"ID du document avec le score le plus élevé : {top_id}\")\n",
    "print(f\"Score : {top_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885762cf-ce47-4ddc-8774-d659cbb34ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b202e4-073c-4f50-9616-cd4b2e63fcb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a98ae-4452-4372-99b8-9da01da6f44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0f68ac0-2dfa-45c2-a7f1-4c906686d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query, num_results=5):\n",
    "    query_vector = embedding_model.encode(query)\n",
    "    \n",
    "    search_query = {\n",
    "        \"size\": num_results,\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\"match_all\": {}},\n",
    "                \"script\": {\n",
    "                    \"source\": \"cosineSimilarity(params.query_vector, 'text_vector') + 1.0\",\n",
    "                    \"params\": {\"query_vector\": query_vector.tolist()}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=index_name, body=search_query)\n",
    "    return [hit['_id'] for hit in response['hits']['hits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b4dcafa-268c-439e-8133-0fc33fa8e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elastic_hitrate(ground_truth, num_results=5):\n",
    "    hits = 0\n",
    "    total = len(ground_truth)\n",
    "    \n",
    "    for item in ground_truth:\n",
    "        query = item['question']\n",
    "        expected_id = item['document']\n",
    "        \n",
    "        results = elastic_search(embedding_vector, num_results=num_results)\n",
    "        \n",
    "        if expected_id in results:\n",
    "            hits += 1\n",
    "    \n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb764327-82df-47d7-833e-5a330b17c8df",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcalculate_elastic_hitrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[83], line 9\u001b[0m, in \u001b[0;36mcalculate_elastic_hitrate\u001b[1;34m(ground_truth, num_results)\u001b[0m\n\u001b[0;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m expected_id \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43melastic_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expected_id \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     12\u001b[0m     hits \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[78], line 2\u001b[0m, in \u001b[0;36melastic_search\u001b[1;34m(query, num_results)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melastic_search\u001b[39m(query, num_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     query_vector \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     search_query \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_results,\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m         }\n\u001b[0;32m     15\u001b[0m     }\n\u001b[0;32m     17\u001b[0m     response \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39msearch(index\u001b[38;5;241m=\u001b[39mindex_name, body\u001b[38;5;241m=\u001b[39msearch_query)\n",
      "File \u001b[1;32m~\\.virtualenvs\\llmzoomcamp-nAbKfTAh\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:485\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[0;32m    484\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentences_sorted[start_index : start_index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m--> 485\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "File \u001b[1;32m~\\.virtualenvs\\llmzoomcamp-nAbKfTAh\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:922\u001b[0m, in \u001b[0;36mSentenceTransformer.tokenize\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: Union[List[\u001b[38;5;28mstr\u001b[39m], List[Dict], List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[0;32m    912\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;124;03m    Tokenizes the texts.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m            \"attention_mask\", and \"token_type_ids\".\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\llmzoomcamp-nAbKfTAh\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:154\u001b[0m, in \u001b[0;36mTransformer.tokenize\u001b[1;34m(self, texts, padding)\u001b[0m\n\u001b[0;32m    152\u001b[0m batch1, batch2 \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_tuple \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[1;32m--> 154\u001b[0m     batch1\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtext_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    155\u001b[0m     batch2\u001b[38;5;241m.\u001b[39mappend(text_tuple[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    156\u001b[0m to_tokenize \u001b[38;5;241m=\u001b[39m [batch1, batch2]\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "calculate_elastic_hitrate(ground_truth,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
